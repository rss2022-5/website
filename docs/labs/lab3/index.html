<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.16">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-rh="true">Lab 3 - Perks of Being a Wallfollower | MIT Robotics Science and Systems Group 5 2022</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://rss2022-5.github.io//website/docs/labs/lab3"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Lab 3 - Perks of Being a Wallfollower | MIT Robotics Science and Systems Group 5 2022"><meta data-rh="true" name="description" content="Wallfollower"><meta data-rh="true" property="og:description" content="Wallfollower"><link data-rh="true" rel="icon" href="/website/img/car.ico"><link data-rh="true" rel="canonical" href="https://rss2022-5.github.io//website/docs/labs/lab3"><link data-rh="true" rel="alternate" href="https://rss2022-5.github.io//website/docs/labs/lab3" hreflang="en"><link data-rh="true" rel="alternate" href="https://rss2022-5.github.io//website/docs/labs/lab3" hreflang="x-default"><link rel="stylesheet" href="/website/assets/css/styles.961fa701.css">
<link rel="preload" href="/website/assets/js/runtime~main.77f6d3be.js" as="script">
<link rel="preload" href="/website/assets/js/main.32b19255.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/website/"><div class="navbar__logo"><img src="/website/img/logo.svg" alt="Robot" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/website/img/logo.svg" alt="Robot" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">MIT Robotics Science and Systems Group 5 2022</b></a><a class="navbar__item navbar__link navbar__link--active" href="/website/docs/intro">Labs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/rss2022-5" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">🌜</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">🌞</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode (currently light mode)"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/website/docs/intro">Welcome!</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/website/docs/labs/lab3">Lab Reports</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/website/docs/labs/lab3">Lab 3 - Perks of Being a Wallfollower</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/website/docs/labs/lab4">Lab 4</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/website/docs/labs/lab5">Lab 5 - Pocket Full of Poses</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/website/docs/labs/lab6">Lab 6 - Pure Pursuit of Happyness</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/website/docs/Presentations/lab3">Presentations</a></div></li></ul></nav></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Xlws" aria-label="breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><span class="breadcrumbs__link breadcrumbsItemLink_e5ie">Lab Reports</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><a class="breadcrumbs__link breadcrumbsItemLink_e5ie" href="/website/docs/labs/lab3">Lab 3 - Perks of Being a Wallfollower</a></li></ul></nav><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Lab 3 - Perks of Being a Wallfollower</h1><h2 class="anchor anchorWithStickyNavbar_mojV" id="wallfollower">Wallfollower<a class="hash-link" href="#wallfollower" title="Direct link to heading">​</a></h2><h2 class="anchor anchorWithStickyNavbar_mojV" id="introduction">Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">​</a></h2><p>[Carolina]</p><p>The primary goal of this lab was to practice configuring, publishing and running code on our racecar.  It is important for our team to become very comfortable with the process of setting up our robot hardware, as this is something we will repeat throughout the semester in every future lab. In this lab, we adapted previously-written code from Lab 2:Wall-Follower Simulation to enable our racecar to autonomously follow a wall at a certain distance. Adapting this code from a simulation to a real-world environment presented technical challenges. Finally, we implemented a safety controller that prevents our robot from incurring damage – a key element of a physical robot platform that was previously unnecessary in the simulation context. We took a unique approach to our wall follower by implementing a nested feedback loop controller, and then created an effective safety controller.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="technical-approach">Technical Approach<a class="hash-link" href="#technical-approach" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="initial-set-up-and-hardware-configuration">Initial Set Up and Hardware Configuration<a class="hash-link" href="#initial-set-up-and-hardware-configuration" title="Direct link to heading">​</a></h3><p>[Carolina]</p><p>The initial portion of this lab involved configuring our robot’s hardware and connecting it to the router, which allows us to publish code to the robot. At first, the car would not connect to our router, but after physically connecting the car to a monitor, keyboard and mouse, we were able to visualize its settings and enable automatic sign in to avoid this issue in the future.</p><p>We then tested several hardware components located on or linked to our robot. First, we ensured that we could control our robot manually with the joystick – this is important to be able to override our autonomous code in case of unexpected errors, or to be able to control the robot for testing programs that don’t automate its movement. We ran test files and also demoed the joystick on our own. </p><p>Once we ensured the joystick was functioning, we moved on to testing our car’s IMU. Although we haven’t used the IMU yet during a lab, we know that the features of the IMU (the gyroscope and accelerometer) will be useful in the future to allow our robot to perform dead reckoning. </p><p>Finally, we tested the lidar sensor. The lidar acts as the eyes of our robot and allows it to perceive objects through laser scanning that sends the robot the distances of a series of points in its vision. We need lidar data to be able to detect walls and other objects for future labs. To test the lidar scanner, we visualized the lidar data using RVIZ (running roscore on our robot). We then put our hands in front of the robot and watched how the data points on RVIZ responded. We also ran our wall follower code and visualized the lidar data, as shown in Figure 2.1.1. Below.</p><img src="/website/assets/images/1-f10d81813b3e79611603e05d56c55692.png" alt="Example banner" style="height:250px"><img src="/website/assets/images/2-b4a6cdf1fb712d27da57638f82d5c742.png" alt="Example banner2" style="height:250px"><p><strong>Figure 2.1.1</strong>. RVIZ visualization of lidar data (left) and IMU (right)</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="wall-follower-implementation">Wall Follower Implementation<a class="hash-link" href="#wall-follower-implementation" title="Direct link to heading">​</a></h3><p>[Vedang Lad, Quinn Bowers]</p><p>The car uses negative feedback to maintain its distance to the wall. The car first uses lidar to detect its relative position to the wall. A controller then reads the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">error</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">error</span></span></span></span></span>, or the difference between desired distance (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">d_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>),  and actual distance (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span></span>), and outputs a new steering angle for the car. </p><p>The car’s lidar detector produces a list of 2D points. Processing these to produce an estimation of wall location can be sensitive to outliers. To detect the wall, we run a linear regression on a subset of the points, selected based on which side we expect the wall to be on. Weighting the points by <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msup><mi>r</mi><mn>3</mn></msup></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{r^3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span> allows the regression to treat closer points as more &quot;important&quot; than distant ones. This weighting scheme has two main benefits. Firstly, the linear regression passively rejects outliers. The lidar module sometimes returns a distance of max_distance instead of the actual distance to an object at the reported angle. These points are given negligible weight, and so will not throw off the wall detection. The other benefit of this weighting scheme is how it responds to corners. Decreasing the weight of distant points allows the robot to look straight ahead. Points that are far away and far from the wall will also not throw off the wall detection. Once the robot is close enough to the corner that it should begin turning, the points straight ahead will have enough weight to change the wall detection, causing the robot to begin to turn.</p><p>There are two key ingredients that make our wall follower implementation different from other groups. The first is the use of two nested proportional gain controllers, which allows for greater wall tracking abilities. This is particularly useful in situations where the racecar can lose the wall, such as wall protrusions and hidden corners. While one controller tracks the angle the other controller tracks the wall distance. This unique nested structure prevents overcorrection errors that can be seen in a standard PID controller.</p><img src="/website/assets/images/3-3aecc300ba2cd6da43a9ee48841b7dcf.png" alt="Example banner3" style="height:150px"><p><strong>Figure 2</strong> Block Diagram of the wall follower feedback loop. The inner feedback loop controls the angle of the car with respect to the wall, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>h</mi><mi>e</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span></span></span></span></span>. The outer feedback loop controls the distance of the car with respect to the wall.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="safety-controller-implementation">Safety Controller Implementation<a class="hash-link" href="#safety-controller-implementation" title="Direct link to heading">​</a></h3><p>[Ishita Goluguri]</p><p>The safety controller is a program that runs on the robot alongside all other programs. Its purpose is to prevent the robot from crashing into sudden obstacles, whether it is a person walking into its path or another robot. However, the safety controller cannot be restrictive and prevent the robot from its actual functionality, which in this lab, was to follow the wall. </p><p>As an overview, the Safety Controller takes the current path of the robot and uses this to predict the robot’s trajectory over a certain brake time, which is currently set to be 0.5 seconds. If there are obstacles detected within a minimum safe distance from the trajectory, which is currently 0.5 meters, then the robot stops immediately.</p><p>The safety controller utilizes one publisher and two subscribers. The publisher, ackermann_publisher, publishes messages of the type AckermannDriveStamped to the topic
<code>/vesc/low_level/ackermann_cmd_mux/input/safety</code>. As seen in Figure 2.4.1, these messages get the second highest priority, with only the joystick getting higher priority. The safety controller also takes precedence over the AckermannDriveStamped messages published to the navigation topics: &quot;/vesc/low_level/ackermann_cmd_mux/input/nav_i.&quot; The two subscribers, drive_subscriber and lidar_subscriber subscribe to the topics <code>/vesc/low_level/ackermann_cmd_mux/output</code> and <code>/scan</code> respectively. The drive_subscriber retrieves the AckermannDriveStamped messages navigating the car at any given time, and the lidar_subscriber retrieves information about objects around the robot through lidar data. </p><center><img src="/website/assets/images/4-0eea3058adab9b509414478958b16dc8.png" alt="Example banner4" style="height:300px"></center><p><strong>Figure 2.4.1</strong> Slide from 6.141 lecture</p><p>The drive_subscriber calls the function drive_callback, which sets the car’s speed and angle to the current values in the class variables. The lidar_subscriber calls the function lidar_callback, which analyzes the LiDAR data to determine if the robot should halt. </p><p>The function lidar_callback begins by creating a point array, which contains the x and y coordinates of the lidar points with respect to the robot as the origin: </p><div class="codeBlockContainer_I0IT language-jsx theme-code-block"><div style="color:#393A34;background-color:#f6f8fa" class="codeBlockTitle_BvAR">safety_controller/src/safety_controller.py</div><div class="codeBlockContent_wNvx jsx"><pre tabindex="0" class="prism-code language-jsx codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">points </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"> r</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">cos</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">theta</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> r</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">sin</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">theta</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> r</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> theta</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> r</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> theta </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">zip</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ranges</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> angles</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>This function takes the data.ranges values, which are passed in as a series of angles with corresponding distances, and converts it to cartesian coordinates The x-coordinate was increased by 0.3 to translate the points from coordinates with respect to the lidar frame to point with respect to the robot frame. </p><p>Next, the curvature is calculated from the car’s current steering angle by taking the reciprocal of the radius.  <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mfrac><mn>1</mn><mi>R</mi></mfrac><mo>=</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>s</mi><mi>t</mi><mi>e</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>a</mi><mi>n</mi><mi>g</mi><mi>l</mi><mi>e</mi><mo stretchy="false">)</mo></mrow><mi>L</mi></mfrac></mrow><annotation encoding="application/x-tex">K = \frac{1}{R} = \frac{sin(steering\_angle)}{L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.397em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.052em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.527em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">in</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">eer</span><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mtight" style="margin-right:0.02778em">_</span><span class="mord mathnormal mtight">an</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">e</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>, where L and steering_angle are as shown in the diagram. We chose to use the curvature rather than the radius, because the radius can approach infinity and thus has no limit, but the curvature approaches 0. Next, the look-ahead distance is computed by multiplying break_time, velocity, and the safety_factor. These factors were chosen because they took into account the amount of distance the robot was predicted to move before it could stop (break_time*velocity), and also a little bit of extra distance for safety purposes, which is added through the safety_factor. In addition, there is a minimum_safe_distance that points must be away from the robot’s trajectory to account for the width of the robot and any error.</p><center><img src="/website/assets/images/8-fd2724439128895288b07478938162f6.png" alt="Example banner8" style="height:500px"></center><p><strong>Figure 2.4.2</strong> Diagram describing variables in trajectory prediction. <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span></span> is the length of the car and remaining parts are as labeled.</p><p>Next, we check if there are any points that fall in the danger zone described above. We also throw out any points that are too close to the LiDAR, which are the sensor detecting the robot itself, and any points with angles less than <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>π</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{\pi}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0404em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span> or greater than <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>π</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{\pi}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0404em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>. This prevents the robot from sensing points behind itself.</p><p>The points from the LiDAR are converted back into polar coordinates with respect to the robot’s center of origin, and checked to see if they are in the problematic region. It’s important to note that the robot’s center of rotation is not the same as the center of the robot, but is needed to determine whether the points fall in its trajectory, thus necessitating the switch from the given data to cartesian coordinates and then back to polar coordinates. </p><p>If the points are within the danger zone, they are appended to the danger array. If the danger array is nonempty after scanning through all the allowed LiDAR points, a stop command is sent through the method send_stop_message(). The method publishes a drive message with speed 0 and angle 0 using ackermann_publisher. This stop command takes precedence over the navigation commands and stops the robot immediately. In the case that no danger points are detected, no stop command is sent, and the robot navigates normally.</p><center><img src="/website/assets/images/7-6c112a0e0b9c250cae6510b0057a3c42.gif" alt="Example banner3.0" style="height:300px"></center><p>Figure 2.4.3 Video demo of the car following the wall via the wall follower code, and reacting to an unexpected object in the path via safety controller commands</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="experimental-evaluation">Experimental Evaluation<a class="hash-link" href="#experimental-evaluation" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="experimental-procedure-parameters-and-purpose">Experimental Procedure, Parameters and Purpose<a class="hash-link" href="#experimental-procedure-parameters-and-purpose" title="Direct link to heading">​</a></h3><p>[Quinn Bowers]</p><p>To evaluate the effectiveness of our wall follower, we measured its response to a step input, both in reality and in simulation. To create a step response, the robot was driven along a wall that jutted suddenly outwards, as shown in figure 3.1.1. This wall was assembled with cardboard boxes in reality, and was drawn manually in simulation.</p><p>The step response of the car was then analyzed. Because we do not currently have a reliable method of determining the car’s location in space available to us, we instead examined the error signal over time. The step response can be analyzed to determine the peak error and the time it takes for the car to settle back into equilibrium, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">t_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. Our design goal is to minimize these values as much as possible; a high peak error means that the car may be too far away from the wall, or too close. If the error ever exceeds the target distance, this implies the car has crashed. A large settling time often implies that the car is oscillating for a long time, causing it to waste motion. A high peak error is unsafe. A high settling time is wasteful. The analysis in the following sections shows that our controller has very acceptable error and settling time at low speeds, but can sometimes fail at high speeds.</p><img src="/website/assets/images/5-8dcbd37c55684f64a01b7c236b1f0b50.png" alt="Example banner5" style="height:500px"><p><strong>Figure 3.1.1</strong>  The robot navigating a custom simulation. We used a custom map to determine the robot’s response to stimuli in a variety of different target distances and speeds.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="simulated-robot-evaluation">Simulated Robot Evaluation<a class="hash-link" href="#simulated-robot-evaluation" title="Direct link to heading">​</a></h3><p><strong>Figures 3.2.1-3</strong> depict the step responses of the simulated robot. Each figure shows the response of the robot at different target distances, but the same speed. From the figures, it can be observed that both maximum error and settling time increase with target distance. It is interesting to note that maximum error does not seem to increase with speed. Settling time decreases with speed, which matches the fact that the car is moving faster and able to adapt more quickly.</p><center><img src="/website/assets/images/05-f53c2944ed29866f15001f9635b9e495.png" alt="Example banner.5" style="height:500px"></center><p><strong>Fig 3.2.1</strong> Step response of the simulation car with different target distances. All cars are traveling at 0.5m/s.</p><center><img src="/website/assets/images/10-4b73a6d3d631a63c6df5547f9d30817a.png" alt="Example banner1.5" style="height:500px"></center><p><strong>Fig 3.2.2</strong> Step response of the simulation car with different target distances. All cars are traveling at 1m/s.</p><center><img src="/website/assets/images/30-358eaa3cc69af4eaa842859aab6b5cc1.png" alt="Example banner3.0" style="height:500px"></center><p><strong>Fig 3.2.3</strong> Step response of the simulation car with different target distances. All cars are traveling at 3m/s.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="physical-robot-evaluation">Physical-robot evaluation<a class="hash-link" href="#physical-robot-evaluation" title="Direct link to heading">​</a></h3><p>Evaluating the physical robot was not nearly as smooth. The car suffered a number of technical difficulties that took some time to resolve, reducing the amount of analysis we could do. Additionally, real-world data is seldom as clear as simulated data. Figure 3.3.3 shows an experimental step response of the car. The time steps between data points are noticeably less uniform than simulation data, and the error reading is noisier. Figure 3.3.4 shows another step response with even more noise. The real-world data was sufficiently noisy and inconsistent that it could not be analyzed the same way the simulation data was. Indeed, much of our real-world data had to be completely thrown out.</p><p>Nonetheless, there are still conclusions to be drawn from our experiments. Figure 3.3.5 shows a step response where the car oscillates. This behavior is also shown in Figure 3.2.1. No oscillation was observed in the simulation. This implies a mismatch between the car in reality and the car we modeled. This mismatch is to be expected, however we did not anticipate the dynamics of the hardware car to be different enough to cause semi-stability in our controller.</p><p>We can also notice that in many cases, the car responds quite well to step responses. Figure 3.3.3 shows a characteristic step response of the car traveling at low speeds. The peak error is only 0.25 meters, and the settling time is roughly one second.</p><p>Finally, we note that the car behaves more stably at a greater distance from the wall. Figures 3.3.5 and 3.3.4 depict step responses of the car moving at the same speed, however the car is 1.5 meters from the wall in figure 3.3.4 and only 1 meter from the wall in figure 3.3.5. When further away, the response is still messy, but does not feature the same large oscillations as in the near case.</p><center><img src="/website/assets/images/6-d1fd75f8dd326851f0b7c06d5e444e31.gif" alt="Example banner3.0" style="height:500px"></center><p><strong>Figure 3.2.1</strong> The hardware car following the wall. The inner loop gain has not yet been adjusted. The car oscillates semi-stably as it follows the wall. </p><center><img src="/website/assets/images/mat1-2f5f772a02284d9bbeaa6a2152f6d5a9.png" alt="Example banner3.0" style="height:500px"></center><p><strong>Figure 3.3.3</strong> Step response of the hardware car. Target distance is 0.5m, and car velocity is 0.5m/s.</p><center><img src="/website/assets/images/mat2-e65aecd6241e62ab41e3ba7474ecd76d.png" alt="Example banner3.0" style="height:500px"></center><p><strong>Figure 3.3.4</strong>  Step response of the hardware car. Target distance is 1.5 meters, and car velocity is 3m/s.</p><center><img src="/website/assets/images/mat3-89f8df613537625052ee91a620149fea.png" alt="Example banner3.0" style="height:500px"></center><p><strong>Figure 3.3.5</strong> hardware step response. Target distance is 1m, and car velocity is  3m/s. The car oscillates noticeably after the step response, and is in fact only semi-stable. These oscillations do not decay with time.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>[Vedang Lad]</p><p>In this design phase, we constructed an essential framework for success. Just like a human, for a robot to successfully interact with its environment, it must learn to navigate it safely. We achieve this by implementing an accurate wall-following mechanism that ensures collision-free motion regardless of the shape of the wall. Unlike other PID controllers, our group’s controller is unique in that it nests two proportional controllers, not one. This mechanism prevents losing the walls on turns since the outer controller can correct errors of the inner controller. An onboard safety controller brings the robot to a smooth stop in the event of a collision, which is a similar feature to life-saving auto-brake mechanisms that have become a standard feature on cars today. </p><p>Due to our robust simulator code, we can seamlessly transition from a simulated robot to one in the real world. We test the robot in three different environments to ensure its success. The first is on an elevated box, which confirms successful wall detection and eliminates the possibility of collision. The second environment is a classroom wall, which tests for wall following in an obstacle-free environment. The third and most challenging test is in the basement of Stata. While also testing the safety controller, the group ensures the robot’s success is not environment-specific. </p><p>Rigorous testing and problem solving would be impossible without collaboration and resourcefulness. For instance, when faced with connectivity issues, the group found a nearby TV, mouse, and keyboard to find a solution. If challenged by an unsolved bug, all group members pause their respective work and attack the problem together. When stuck, the group asks for guidance on how to solve the issue at hand. For instance, when “phantom” lidar points appeared on the robot and rigorous troubleshooting did not find a solution, reaching out to the TA enabled the group to reach the solution. </p><p>Overall, the group completed the lab, creating a seamless transition to the next lab. We are excited to take on a new problem after this lab. More importantly, we look forward to continuing our pursuit of cultivating strong technical and interpersonal skills. By introducing a vision system, we will be able to navigate now with eyes allowing the robot to make smarter decisions in the environment. Instead of following a wall, the robot will follow a line that requires higher precision in movements. Furthermore, it will learn to stop in the presence of a cone. While more information means higher complexity, the group is ready to tackle this next challenge with the same drive as we did the first. </p><h2 class="anchor anchorWithStickyNavbar_mojV" id="lessons-learned">Lessons Learned<a class="hash-link" href="#lessons-learned" title="Direct link to heading">​</a></h2><p><strong>Vedang Lad</strong> Time management was the essential ingredient that I learned from this lab. Having taken advanced physics and mathematics classes, I had a strong understanding of the principles of PID controllers; however, I did not anticipate the time taken to design, test, and implement my own. Luckily, with the help of all my group members, we completed all of our assignments promptly. A key lesson I learned in collaboration was that more is not always better. When each group member found a different role to fill, we were far more productive and had a much clearer direction instead of everyone working on one assignment. We divided up the work to ensure that we were efficient with our time. A key lesson in communication that I learned was not to be ashamed to ask for help. After spending an hour trying to figure out why mysterious points were appearing on the lidar sensor around our robot, I reached out to a TA for help. It turned out that that robot was detecting itself on the lidar, a common issue. At that moment, I realized the importance of struggling with a problem and recognizing when to reach out for help. I hope to build on the ever-growing skill set as we continue work on the labs. </p><p><strong>Ishita G</strong> A key skill I learned during this lab was splitting work up efficiently. A strategy I’ve used in past group work is to take the same work and split it up evenly among the different members of the group. However, in this lab, we split it up according to our various strengths, and as a result, we got it done much faster than we would have otherwise. In addition, we ran into many challenges. Sometimes, there was no viable explanation other than that it simply does not work. While momentary frustration is expected and understandable, it was important for us to progress past that feeling and think together about how to improve together. In addition, our team learned a lot about the resources available to us as a result of the challenges we faced. We initially tried to figure everything out by ourselves, but after we realized it wasn’t working, we branched out to asking other classmates, asking on Piazza, and asking a TA during office hours. Many of our issues were solved through a combination of all three of these methods. Working on this lab and going through the initial setup taught me many strategies that I can continue to use throughout this class  and beyond.</p><p><strong>Carolina W</strong> Perseverance despite frustration was a key skill learned during this lab. Our team faced a number of challenges, from missing Ethernet cables, problematic router connections, and unusual IMU errors to hidden bugs in our code. We practiced resourcefulness, collaborating as a team to locate replacement hardware from wherever we could find it – borrowing cables from friends in our dorms and using the TVs in lounges as monitors. Being resourceful helped us to bypass these issues and continue to make progress on the lab without becoming stuck. Additionally, we found it was complicated at first to communicate when there were so many different elements of the lab that needed to be addressed – however, we found that using a messenger chat to stay up-to-date with one another was an effective strategy.
I personally became very comfortable with the setup process involved in using the robot – what hardware needs to be connected and what commands need to be run in terminal before we can start pushing code to the robot. I also learned how to use RVIZ effectively to visualize Lidar and IMU data, which will be very useful as we pursue future labs.</p><p><strong>Quinn Bowers</strong> One of the biggest lessons I learned over the course of this lab was the necessity of taking clear, copious notes. I frequently found myself looking up the same linux commands. This was not too much of a challenge or use of time, but the same lesson applied to debugging; After spending multiple hours fixing the robot’s connection to the joystick, I forgot a small, crucial detail and spent another several hours debugging the same issues. Having these lessons written down will help not only myself, but also democratize our progress to avoid one person knowing all the tips and tricks.
Another important lesson is to keep organizational frameworks as consistent as possible. We switched up our github repository structure twice (once to a new layout, then back when the TA’s told us this was a bad idea), and while this did not take too much time, the back and forth made it tricky to keep everyone up-to-date on how to stay organized.
As a final note, I need to get better at figuring out when to pass off my knowledge and hand off tasks to others, or to just buckle down and hammer them out. I have a reasonable degree of linux experience, and often found myself scrambling to get things set up and running so others could get to work. I also have a tendency to underestimate how long tasks will take to complete. It is likely that I should be teaching these tasks to other people, to decrease my personal workload and also ensure the team is equally functional without me.</p><h1>Presentation</h1><iframe src="https://docs.google.com/presentation/d/e/2PACX-1vR2Eh7WcskS73aO5SZC7rW9dOokaPHZT-3pCG_Qktys0WvX8QmcUXYEgAkbqzChheZvrAl_2brU_j69/embed?start=false&amp;loop=false&amp;delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe><h1>Download Links</h1><p>Briefing Slides:
<a href="https://drive.google.com/uc?export=download&amp;id=1K6Bw0W8B6EbHfb0qX5gAUZi1J8CbdwZb" target="_blank" rel="noopener noreferrer">Download Slides</a></p><p>Report:
<a href="https://drive.google.com/uc?export=download&amp;id=12nw-yAH_1OdclmKdbIHxcGwP9RZhiaW4" target="_blank" rel="noopener noreferrer">Download Report</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/rss2022-5/docs/labs/lab3.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/website/docs/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Welcome!</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/website/docs/labs/lab4"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Lab 4</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#wallfollower" class="table-of-contents__link toc-highlight">Wallfollower</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#technical-approach" class="table-of-contents__link toc-highlight">Technical Approach</a><ul><li><a href="#initial-set-up-and-hardware-configuration" class="table-of-contents__link toc-highlight">Initial Set Up and Hardware Configuration</a></li><li><a href="#wall-follower-implementation" class="table-of-contents__link toc-highlight">Wall Follower Implementation</a></li><li><a href="#safety-controller-implementation" class="table-of-contents__link toc-highlight">Safety Controller Implementation</a></li></ul></li><li><a href="#experimental-evaluation" class="table-of-contents__link toc-highlight">Experimental Evaluation</a><ul><li><a href="#experimental-procedure-parameters-and-purpose" class="table-of-contents__link toc-highlight">Experimental Procedure, Parameters and Purpose</a></li><li><a href="#simulated-robot-evaluation" class="table-of-contents__link toc-highlight">Simulated Robot Evaluation</a></li><li><a href="#physical-robot-evaluation" class="table-of-contents__link toc-highlight">Physical-robot evaluation</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li><li><a href="#lessons-learned" class="table-of-contents__link toc-highlight">Lessons Learned</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Labs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/website/docs/intro">Labs</a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/rss2022-5" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 RSS Team 5, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/website/assets/js/runtime~main.77f6d3be.js"></script>
<script src="/website/assets/js/main.32b19255.js"></script>
</body>
</html>